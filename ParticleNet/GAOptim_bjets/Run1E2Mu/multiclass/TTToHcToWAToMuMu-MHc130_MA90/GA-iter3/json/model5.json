{
  "hyperparameters": {
    "signal": "MHc130_MA90",
    "channel": "Run1E2Mu",
    "iteration": 3,
    "model_idx": 5,
    "num_hidden": 128,
    "optimizer": "RMSprop",
    "initial_lr": 0.0007,
    "weight_decay": 1e-05,
    "scheduler": "CyclicLR",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.4,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 16,
    "best_train_loss": 0.827112981863801,
    "best_valid_loss": 0.8632517474926977,
    "best_train_acc": 0.6680428725416421,
    "best_valid_acc": 0.6505966276024695,
    "total_epochs": 24
  },
  "epoch_history": {
    "train_loss": [
      0.9426235317599599,
      0.9072776061580976,
      0.8794436900353703,
      0.8820499122168248,
      0.8662688320499494,
      0.8642592827671387,
      0.858552415995148,
      0.8521172692766077,
      0.8388583985132214,
      0.8451976518313471,
      0.8520957154651022,
      0.8627640177975731,
      0.8536226260441209,
      0.8602745245300627,
      0.8438747671108272,
      0.8356243555055431,
      0.827112981863801,
      0.8487455266912055,
      0.8535643051579755,
      0.8479608386922884,
      0.8531919893704164,
      0.8414292176910427,
      0.834618494231302,
      0.8312960303751773
    ],
    "valid_loss": [
      0.9773553766291586,
      0.9404112111859483,
      0.9153257467791062,
      0.9124786882861241,
      0.8998776164511813,
      0.9061046405563556,
      0.8928369901186793,
      0.8872161632711917,
      0.8761379211521972,
      0.8790842511849374,
      0.8885781113133593,
      0.8960227987553842,
      0.889306240744232,
      0.8991238234840977,
      0.8778811940916204,
      0.8693368106706478,
      0.8632517474926977,
      0.8832833391726967,
      0.8862336474007059,
      0.8830999100529363,
      0.8908523201746095,
      0.8776613222297058,
      0.8735105703450864,
      0.8700456870250438
    ],
    "train_acc": [
      0.6029612153999471,
      0.6240883483495698,
      0.6417315788403262,
      0.6366918180154162,
      0.6505196363562408,
      0.6521060017490695,
      0.6513921373222966,
      0.6561593687079257,
      0.662460086639956,
      0.661298785820334,
      0.6561654701132827,
      0.6463808497223861,
      0.6581728324757469,
      0.6512212979722997,
      0.659706319022148,
      0.6657894201631109,
      0.6680428725416421,
      0.6532978095954768,
      0.6536049136651142,
      0.6598059753096464,
      0.6562325855722101,
      0.6619373995810368,
      0.6654884174988306,
      0.6669080111452338
    ],
    "valid_acc": [
      0.5861229278003579,
      0.6058702942256876,
      0.6228448531241483,
      0.6212155324619923,
      0.6328222203789504,
      0.6324608074320721,
      0.6348840516168786,
      0.6382789633965708,
      0.6450332381415079,
      0.6448317948596415,
      0.6371591757414891,
      0.6310862532734534,
      0.6413124622293846,
      0.6334087758173265,
      0.6421063857520352,
      0.6490443293716155,
      0.6505966276024695,
      0.6375561375028143,
      0.6372539725800145,
      0.6420826865424039,
      0.6389010676493939,
      0.6449621405126139,
      0.6474624071287223,
      0.6484577739332393
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23
    ],
    "timestamp": [
      1762307001.4832501,
      1762307113.8904293,
      1762307223.6566913,
      1762307332.9773822,
      1762307443.1440263,
      1762307551.43728,
      1762307657.5978632,
      1762307752.3389537,
      1762307861.6225111,
      1762307969.4176846,
      1762308076.244986,
      1762308183.2404113,
      1762308287.4790833,
      1762308374.0564818,
      1762308480.5415702,
      1762308582.2788055,
      1762308682.4096756,
      1762308783.9807003,
      1762308884.742885,
      1762308971.9414022,
      1762309074.3059797,
      1762309178.0020392,
      1762309279.562727,
      1762309378.9918725
    ]
  }
}