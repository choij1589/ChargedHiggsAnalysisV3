{
  "hyperparameters": {
    "signal": "MHc115_MA87",
    "channel": "Run1E2Mu",
    "iteration": 0,
    "model_idx": 14,
    "num_hidden": 128,
    "optimizer": "RMSprop",
    "initial_lr": 0.003,
    "weight_decay": 0.00849,
    "scheduler": "ReduceLROnPlateau",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.3,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 1,
    "best_train_loss": 0.8886930845445209,
    "best_valid_loss": 0.9034837950875351,
    "best_train_acc": 0.675581104723819,
    "best_valid_acc": 0.667262436699434,
    "total_epochs": 9
  },
  "epoch_history": {
    "train_loss": [
      1.281368370652214,
      0.8886930845445209,
      2.7764199342073326,
      1.7253836840125316,
      1.0508740449956733,
      0.980077021072396,
      1.693860505607767,
      0.9010342109399471,
      1.2400843766414353
    ],
    "valid_loss": [
      1.3331136176630283,
      0.9034837950875351,
      2.7529392734655014,
      1.8100778534190505,
      1.0531518130308906,
      0.9984365586174546,
      1.7641383096429664,
      0.9157265556557651,
      1.2506878346836212
    ],
    "train_acc": [
      0.4891783519637332,
      0.675581104723819,
      0.3121827301795241,
      0.48838006015737445,
      0.5521776883365366,
      0.6332468606986185,
      0.48838006015737445,
      0.6861043359849692,
      0.44802161528583373
    ],
    "valid_acc": [
      0.4666409775001161,
      0.667262436699434,
      0.3335956907789557,
      0.4661326599492229,
      0.5445775361902966,
      0.6228803021483249,
      0.4661326599492229,
      0.6816101095069046,
      0.44774577563519197
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8
    ],
    "timestamp": [
      1761018259.8138497,
      1761018723.3929856,
      1761019119.2120934,
      1761019576.631995,
      1761020027.0181456,
      1761020468.9266732,
      1761020915.5094783,
      1761021287.2753654,
      1761021730.274527
    ]
  }
}