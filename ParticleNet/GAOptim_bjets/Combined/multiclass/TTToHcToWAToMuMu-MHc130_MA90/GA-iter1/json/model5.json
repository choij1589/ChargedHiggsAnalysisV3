{
  "hyperparameters": {
    "signal": "MHc130_MA90",
    "channel": "Combined",
    "iteration": 1,
    "model_idx": 5,
    "num_hidden": 128,
    "optimizer": "RMSprop",
    "initial_lr": 0.0019,
    "weight_decay": 0.00097,
    "scheduler": "ReduceLROnPlateau",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.4,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 1,
    "best_train_loss": 1.0604722588034936,
    "best_valid_loss": 1.0911214880374105,
    "best_train_acc": 0.5024653882601293,
    "best_valid_acc": 0.4861245038458951,
    "total_epochs": 9
  },
  "epoch_history": {
    "train_loss": [
      1.1481472547797649,
      1.0604722588034936,
      1.1053953288408715,
      1.2539561788662015,
      1.1462473742764256,
      1.1103706995452676,
      1.3195457039986505,
      1.3142085552924603,
      1.0871746393800625
    ],
    "valid_loss": [
      1.18836320851369,
      1.0911214880374105,
      1.1210330524033538,
      1.2746371340506242,
      1.213562707283154,
      1.149813724516368,
      1.3451088993082005,
      1.3644572489757734,
      1.1267220751177884
    ],
    "train_acc": [
      0.4919855620700016,
      0.5024653882601293,
      0.515050424894258,
      0.42238071758207046,
      0.4917197623982064,
      0.4957683921816375,
      0.4009645831567756,
      0.4689572948527316,
      0.5227432066996925
    ],
    "valid_acc": [
      0.4760108088713475,
      0.4861245038458951,
      0.5070246451236741,
      0.4054952571031328,
      0.4641984167918732,
      0.479912766577714,
      0.39894153790953735,
      0.4564505639898639,
      0.5060547619581549
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8
    ],
    "timestamp": [
      1762475902.9899197,
      1762476140.1031225,
      1762476387.2025654,
      1762476634.7369843,
      1762476882.8262908,
      1762477130.798264,
      1762477379.3228145,
      1762477627.0617666,
      1762477867.0066066
    ]
  }
}