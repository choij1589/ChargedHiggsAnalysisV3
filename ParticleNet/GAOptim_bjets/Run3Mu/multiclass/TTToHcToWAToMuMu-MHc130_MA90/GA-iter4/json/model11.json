{
  "hyperparameters": {
    "signal": "MHc130_MA90",
    "channel": "Run3Mu",
    "iteration": 4,
    "model_idx": 11,
    "num_hidden": 128,
    "optimizer": "RMSprop",
    "initial_lr": 0.0003,
    "weight_decay": 0.00636,
    "scheduler": "ReduceLROnPlateau",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.4,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 15,
    "best_train_loss": 0.9179920291825112,
    "best_valid_loss": 0.938291807828324,
    "best_train_acc": 0.6123991959102006,
    "best_valid_acc": 0.5979958971121982,
    "total_epochs": 23
  },
  "epoch_history": {
    "train_loss": [
      1.059444730097013,
      0.9261148012129786,
      0.9411091666129138,
      0.9433062148772647,
      0.9953323360754303,
      1.0008227831298173,
      0.9234924709657424,
      0.9221904783900134,
      0.9574833511409667,
      0.9407569213831152,
      0.9239713100405482,
      0.9115369175496512,
      0.9382806161649074,
      0.9222862790950728,
      0.9252602990154487,
      0.9179920291825112,
      0.9091903774969201,
      0.9449390250698099,
      0.9088796505820945,
      0.9195365676424784,
      0.9157937192253929,
      0.9152109547332674,
      0.9094687080940109
    ],
    "valid_loss": [
      1.0689044780027896,
      0.9475904258746889,
      0.9586621943092517,
      0.9743626178028921,
      1.0131720459183426,
      1.0469760811502582,
      0.9467486742262549,
      0.9482252104818761,
      0.9952359467652336,
      0.9724944479229336,
      0.9583341100780135,
      0.9404611963255339,
      0.9716258824301145,
      0.944210129743322,
      0.9599796223130019,
      0.938291807828324,
      0.9442925732350601,
      0.9679922445300352,
      0.9427671327651641,
      0.9530049759913617,
      0.952724014337608,
      0.9526647762687659,
      0.9405760295286616
    ],
    "train_acc": [
      0.5198328093004513,
      0.5977536092667132,
      0.6067387036160612,
      0.5931942889006555,
      0.5844739443978464,
      0.5813578621332746,
      0.6085802379468532,
      0.6069144225407551,
      0.5944899231053985,
      0.6025237923424036,
      0.5997896058741665,
      0.6134581952963558,
      0.6050494590200038,
      0.606080343378208,
      0.6107427521800861,
      0.6123991959102006,
      0.6132449896677272,
      0.5490935246404791,
      0.6026971683481015,
      0.6136714009249844,
      0.6151966411913274,
      0.606082686297204,
      0.6140486108833273
    ],
    "valid_acc": [
      0.5338619746462574,
      0.5887972752616906,
      0.5977131660617537,
      0.5858976382094577,
      0.5714257535111251,
      0.553054810372942,
      0.5876137499342486,
      0.5882383883015097,
      0.5665009731208248,
      0.5869759612855715,
      0.5739571826837094,
      0.5982523275998106,
      0.5808019041607491,
      0.5905331124086055,
      0.5987060123086634,
      0.5979958971121982,
      0.591401030982063,
      0.5568552417021724,
      0.576646415233286,
      0.5942546420493399,
      0.5991596970175161,
      0.5799208353058756,
      0.5950436589343012
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22
    ],
    "timestamp": [
      1762310203.9426234,
      1762310289.232511,
      1762310386.6629858,
      1762310483.313168,
      1762310581.5656781,
      1762310679.803192,
      1762310777.553305,
      1762310862.244978,
      1762310963.3576798,
      1762311072.9817884,
      1762311170.4587615,
      1762311264.7794592,
      1762311357.3288972,
      1762311438.3501923,
      1762311528.639434,
      1762311617.5931416,
      1762311707.507395,
      1762311793.6719236,
      1762311877.9619386,
      1762311947.5791838,
      1762312033.9393103,
      1762312117.707083,
      1762312204.550229
    ]
  }
}