{
  "hyperparameters": {
    "signal": "MHc130_MA90",
    "channel": "Run3Mu",
    "iteration": 1,
    "model_idx": 7,
    "num_hidden": 128,
    "optimizer": "RMSprop",
    "initial_lr": 0.0002,
    "weight_decay": 0.00325,
    "scheduler": "ReduceLROnPlateau",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.3,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 15,
    "best_train_loss": 0.792972395422406,
    "best_valid_loss": 0.8054452962503614,
    "best_train_acc": 0.6868005331837123,
    "best_valid_acc": 0.6831483593260629,
    "total_epochs": 23
  },
  "epoch_history": {
    "train_loss": [
      0.8600771847428188,
      0.8096715629902957,
      0.8239401213923744,
      0.8251570031511738,
      0.8153126152851459,
      0.8034945672509977,
      0.8015059527430873,
      0.8146789075648359,
      0.80042009494952,
      0.8130588847013966,
      0.8312347839308163,
      0.8034190328629061,
      0.8392674404660915,
      0.7966203379239968,
      0.8305487060624266,
      0.792972395422406,
      0.8077455756337129,
      0.7984810299990474,
      0.8070965290608446,
      0.8020230583510144,
      0.7953987527945688,
      0.7924933724074266,
      0.8001642429614023
    ],
    "valid_loss": [
      0.8722444975043551,
      0.8213279496076199,
      0.8362012781578906,
      0.8384562335658668,
      0.8248124550203807,
      0.8162472000204172,
      0.8137927269572204,
      0.8256677866606238,
      0.8132342936567167,
      0.8243866567237491,
      0.8429773063277959,
      0.8160500045386448,
      0.8526613976190656,
      0.8092025659662588,
      0.8427765943471742,
      0.8054452962503614,
      0.8198842101198891,
      0.8099561940558939,
      0.8208368169386571,
      0.8154990551789967,
      0.8083410568336561,
      0.8057128615955343,
      0.8140337279517618
    ],
    "train_acc": [
      0.6660421887159688,
      0.6819869810612004,
      0.6834673424976265,
      0.6809329763982204,
      0.6861491107529081,
      0.6837589768705413,
      0.6861094865174576,
      0.6861919049271944,
      0.6860048785358687,
      0.68530115211427,
      0.6801690211387371,
      0.6853391913803023,
      0.6696733536526412,
      0.6863187024806356,
      0.6791974348854939,
      0.6868005331837123,
      0.6846513146528838,
      0.6861903199577765,
      0.6811849865356848,
      0.6850840113040019,
      0.6849017398209302,
      0.6869669549726038,
      0.6857021493770278
    ],
    "valid_acc": [
      0.6635975972117377,
      0.679020574677567,
      0.6803576877981401,
      0.6773260949872312,
      0.6830399447487191,
      0.6807873307527987,
      0.682200735612984,
      0.6829797144279726,
      0.6829114533977931,
      0.6813816032508312,
      0.6765551468816755,
      0.6820642135526253,
      0.6662356852604359,
      0.6826303785676426,
      0.6756436613610446,
      0.6831483593260629,
      0.6811045437753971,
      0.6829114533977931,
      0.6789081447455069,
      0.6816144938243844,
      0.6816305552432502,
      0.6838430156920062,
      0.6820642135526253
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22
    ],
    "timestamp": [
      1760825459.959092,
      1760825818.1721215,
      1760826165.1079617,
      1760826525.486277,
      1760826886.3605092,
      1760827246.3577244,
      1760827625.0370698,
      1760827949.193079,
      1760828294.4456172,
      1760828646.722843,
      1760828987.5681293,
      1760829311.7000425,
      1760829600.3234909,
      1760829932.7013383,
      1760830263.7335443,
      1760830568.5915232,
      1760830812.9844382,
      1760831043.7332904,
      1760831262.0003202,
      1760831468.6858525,
      1760831676.5539675,
      1760831848.260659,
      1760832049.4538972
    ]
  }
}