{
  "hyperparameters": {
    "signal": "MHc100_MA95",
    "channel": "Run3Mu",
    "iteration": 0,
    "model_idx": 15,
    "num_hidden": 96,
    "optimizer": "RMSprop",
    "initial_lr": 0.0022,
    "weight_decay": 0.00918,
    "scheduler": "CyclicLR",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.3,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 1,
    "best_train_loss": 0.8200410479335087,
    "best_valid_loss": 0.8370309596971771,
    "best_train_acc": 0.7019927357753213,
    "best_valid_acc": 0.693377174706773,
    "total_epochs": 9
  },
  "epoch_history": {
    "train_loss": [
      0.8405673648458679,
      0.8200410479335087,
      0.8340208285059385,
      0.9504697726684906,
      1.0429316515786404,
      1.3441298433571056,
      0.8567697438421844,
      1.1001486841429169,
      0.9202673267765558
    ],
    "valid_loss": [
      0.8553371032297097,
      0.8370309596971771,
      0.8520076888266865,
      0.9524256282482652,
      1.0689318102761889,
      1.341664041968695,
      0.8686021521424819,
      1.120584798195885,
      0.9308613648263193
    ],
    "train_acc": [
      0.6956693792568948,
      0.7019927357753213,
      0.6946152128365287,
      0.62116674219884,
      0.5615685733614444,
      0.31561939666213473,
      0.7075065844351178,
      0.43696840127944936,
      0.6691887844574491
    ],
    "valid_acc": [
      0.6884182037963769,
      0.693377174706773,
      0.6870237510778129,
      0.6175238975366044,
      0.5385392901493055,
      0.32822859123145026,
      0.700551592687787,
      0.4363069281196754,
      0.6629880068815004
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8
    ],
    "timestamp": [
      1760709770.264317,
      1760710119.7958417,
      1760710452.1252515,
      1760710806.4338083,
      1760711153.9590452,
      1760711512.9414105,
      1760711836.8338206,
      1760712202.302293,
      1760712508.3747678
    ]
  }
}