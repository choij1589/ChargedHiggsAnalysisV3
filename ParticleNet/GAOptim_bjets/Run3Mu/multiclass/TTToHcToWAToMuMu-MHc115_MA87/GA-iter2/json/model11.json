{
  "hyperparameters": {
    "signal": "MHc115_MA87",
    "channel": "Run3Mu",
    "iteration": 2,
    "model_idx": 11,
    "num_hidden": 96,
    "optimizer": "Adam",
    "initial_lr": 0.0017,
    "weight_decay": 0.00022,
    "scheduler": "CyclicLR",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.3,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 16,
    "best_train_loss": 0.7237903839279363,
    "best_valid_loss": 0.7387269577356238,
    "best_train_acc": 0.7157916153351992,
    "best_valid_acc": 0.710238556502144,
    "total_epochs": 24
  },
  "epoch_history": {
    "train_loss": [
      0.8293604359815706,
      0.7952197269360184,
      0.7818510643989316,
      0.7726151532757453,
      0.7706933901814682,
      0.7584060117003424,
      0.7548868936774691,
      0.7482722870015169,
      0.7397327535695124,
      0.7503322358207501,
      0.7553951167524195,
      0.7553061525397005,
      0.7599703783047908,
      0.7439385829303725,
      0.7392346533322259,
      0.7333572508379891,
      0.7237903839279363,
      0.7340608908709793,
      0.7380189246999161,
      0.7486480317029562,
      0.7503045327820278,
      0.7405706718067138,
      0.7338613208674005,
      0.7277046058569338
    ],
    "valid_loss": [
      0.8461470439865465,
      0.8094530313151638,
      0.7958631372258909,
      0.7868129505084898,
      0.7842707259473702,
      0.7732593387613438,
      0.7696320485213358,
      0.7631376201034059,
      0.7552073525846345,
      0.7657377456137765,
      0.7701555325807601,
      0.7701135962974202,
      0.7740821559157426,
      0.7587698968365698,
      0.7536918177983426,
      0.7483532653792268,
      0.7387269577356238,
      0.7491909775617258,
      0.7528675431263717,
      0.7625805738076291,
      0.762768249232188,
      0.7558078733246919,
      0.7482114708366506,
      0.7426988929963069
    ],
    "train_acc": [
      0.6896530179698852,
      0.692201835597258,
      0.6938326943934022,
      0.6939111934906627,
      0.6998611046585209,
      0.7022673422929105,
      0.7042137995004895,
      0.7071855510396324,
      0.7106523274982338,
      0.7052406958544467,
      0.7037908655887192,
      0.702438758688969,
      0.6998595026361278,
      0.7037107644690658,
      0.710889426812408,
      0.7070974398080137,
      0.7157916153351992,
      0.7121502184357533,
      0.7078840328030105,
      0.7062355517605425,
      0.7080586532438551,
      0.7085985347903193,
      0.7121406063013949,
      0.7130329327743343
    ],
    "valid_acc": [
      0.6855682637982605,
      0.6880608266392148,
      0.689596893820876,
      0.6896049997162936,
      0.695056214384722,
      0.6972569649906377,
      0.699161850413806,
      0.7027730268224079,
      0.7054925547350588,
      0.7001386108116433,
      0.699251015263401,
      0.6977190010294487,
      0.695238597031621,
      0.6993726036946671,
      0.7056465667479959,
      0.702185349404622,
      0.710238556502144,
      0.706842186322112,
      0.7033161218153964,
      0.7009978357259234,
      0.7035674045733462,
      0.7033728630833205,
      0.7066841213614662,
      0.7075595580665818
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23
    ],
    "timestamp": [
      1761079232.6392617,
      1761079614.2532208,
      1761079943.4739897,
      1761080305.1997783,
      1761080679.9577131,
      1761081054.8214788,
      1761081359.7482522,
      1761081711.529047,
      1761082072.8848248,
      1761082439.236449,
      1761082680.1024573,
      1761082950.5919056,
      1761083264.3975847,
      1761083580.180437,
      1761083899.6654894,
      1761084212.8398912,
      1761084889.5001307,
      1761085192.8079562,
      1761085479.9948003,
      1761085781.7681978,
      1761086068.5766573,
      1761086368.9334588,
      1761086670.631999,
      1761086962.793748
    ]
  }
}