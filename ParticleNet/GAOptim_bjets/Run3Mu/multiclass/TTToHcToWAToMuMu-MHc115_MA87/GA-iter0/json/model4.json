{
  "hyperparameters": {
    "signal": "MHc115_MA87",
    "channel": "Run3Mu",
    "iteration": 0,
    "model_idx": 4,
    "num_hidden": 64,
    "optimizer": "RMSprop",
    "initial_lr": 0.0003,
    "weight_decay": 0.00254,
    "scheduler": "ReduceLROnPlateau",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.3,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 19,
    "best_train_loss": 0.795636561888697,
    "best_valid_loss": 0.8083290670847387,
    "best_train_acc": 0.6921746012165758,
    "best_valid_acc": 0.688178362122772,
    "total_epochs": 27
  },
  "epoch_history": {
    "train_loss": [
      0.8089817910837672,
      0.8874784327539774,
      0.8123682980949839,
      0.833234984975893,
      0.8221457184541954,
      0.8041763682726981,
      0.81791539288612,
      0.8315793991635823,
      0.8290527240885769,
      0.8130389394880692,
      0.8353322573283701,
      0.8492041101710236,
      0.8024455494491246,
      0.8115010537740344,
      0.8152356213683373,
      0.8783374307018148,
      0.8104869911017857,
      0.8086153401949152,
      0.8033873267765571,
      0.795636561888697,
      0.7986216106341552,
      0.7986039159819731,
      0.8221779831108792,
      0.7958106898132578,
      0.804948446313157,
      0.8321827701364422,
      0.8029004035886309
    ],
    "valid_loss": [
      0.8229434223718186,
      0.9026055695809271,
      0.8245501707450666,
      0.8474408048087876,
      0.8355980911087288,
      0.8187373878224025,
      0.8323350622651506,
      0.8456027492379192,
      0.8424620803798004,
      0.8258102060652394,
      0.850644045252491,
      0.8654213147393486,
      0.8166895494121927,
      0.8247309570985353,
      0.8278132874058102,
      0.8907823624233233,
      0.8242854143602334,
      0.8225727100006358,
      0.8169787800699431,
      0.8083290670847387,
      0.8128975925870573,
      0.8125661275623496,
      0.8377646427420002,
      0.8092138153778462,
      0.8174532834251347,
      0.8469624137505813,
      0.8164522671841183
    ],
    "train_acc": [
      0.6880413834424578,
      0.6649450266015818,
      0.6914937416995215,
      0.6818175264453846,
      0.6793215755569831,
      0.6916507398940422,
      0.6870513336035411,
      0.6841340508257624,
      0.6859315199507858,
      0.6880830360246776,
      0.6889208937362526,
      0.6714428294278697,
      0.6915690367519958,
      0.6917228309017304,
      0.6927289009645777,
      0.680294003149576,
      0.6917532693271986,
      0.6910964401460403,
      0.6890843000203457,
      0.6921746012165758,
      0.6900839619936208,
      0.6918381765140313,
      0.6814682855636957,
      0.6914168446246541,
      0.6889497301393279,
      0.6888568128405299,
      0.6882576564655221
    ],
    "valid_acc": [
      0.6840200377734726,
      0.6578136778879279,
      0.6875623140710239,
      0.6784067051966896,
      0.677158397302358,
      0.6877041672408343,
      0.6831283892775215,
      0.6805750322209343,
      0.6818314460106836,
      0.6846887741454359,
      0.6853250869357284,
      0.6663978211353118,
      0.687128648666175,
      0.6876028435481125,
      0.688607974579912,
      0.6773650976355103,
      0.6878419674629358,
      0.6868692600128073,
      0.6849765334327657,
      0.688178362122772,
      0.6857628052882861,
      0.6874083020580869,
      0.6773691505832192,
      0.6872988724699474,
      0.6855196284257541,
      0.6850454335438164,
      0.6844374913874861
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26
    ],
    "timestamp": [
      1761040817.2679422,
      1761041130.8443878,
      1761041542.3609195,
      1761041936.108432,
      1761042295.7092185,
      1761042667.685911,
      1761043000.333285,
      1761043368.4804316,
      1761043712.8715436,
      1761044036.9538789,
      1761044332.1315265,
      1761044668.3323064,
      1761044977.1014428,
      1761045281.9061081,
      1761045590.7302895,
      1761045861.5051794,
      1761046131.5442228,
      1761046412.3749437,
      1761046705.1008928,
      1761046984.581715,
      1761047231.1388457,
      1761047507.9730725,
      1761047787.8164852,
      1761048064.241837,
      1761048304.0987175,
      1761048582.869339,
      1761048855.3413572
    ]
  }
}