{
  "hyperparameters": {
    "signal": "MHc160_MA85",
    "channel": "Run3Mu",
    "iteration": 1,
    "model_idx": 12,
    "num_hidden": 96,
    "optimizer": "Adam",
    "initial_lr": 0.0027,
    "weight_decay": 0.00212,
    "scheduler": "CyclicLR",
    "pilot_mode": false,
    "num_classes": 4,
    "model_type": "ParticleNet",
    "num_node_features": 9,
    "num_graph_features": 4,
    "dropout_p": 0.3,
    "batch_size": 1024,
    "train_folds": [
      0,
      1,
      2
    ],
    "valid_folds": [
      3
    ]
  },
  "training_summary": {
    "best_epoch": 1,
    "best_train_loss": 0.8296507504997774,
    "best_valid_loss": 0.8456076298056915,
    "best_train_acc": 0.67468610570761,
    "best_valid_acc": 0.6701650065717588,
    "total_epochs": 9
  },
  "epoch_history": {
    "train_loss": [
      0.8390760980206762,
      0.8296507504997774,
      0.8416712544595699,
      0.8450175782394309,
      0.8511208014977759,
      0.8822412482501798,
      0.855117613587767,
      0.8317742976623341,
      0.8294869152716641
    ],
    "valid_loss": [
      0.8565065131738434,
      0.8456076298056915,
      0.8563286397524666,
      0.8627843550694587,
      0.8671363238931622,
      0.893358671175699,
      0.8709483390488789,
      0.8485528170013826,
      0.8458942403121146
    ],
    "train_acc": [
      0.6732682409243351,
      0.67468610570761,
      0.6727737097195726,
      0.6748660775068115,
      0.6722040598507956,
      0.6670036573399543,
      0.6693605054234111,
      0.6748660775068115,
      0.6757784562801551
    ],
    "valid_acc": [
      0.6689575448542336,
      0.6701650065717588,
      0.6687675180921313,
      0.6707113335128031,
      0.6679876165893364,
      0.6633082075725665,
      0.6655251864637604,
      0.6707509224215744,
      0.6710517981282363
    ],
    "epoch": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8
    ],
    "timestamp": [
      1760931682.4435005,
      1760932050.7312179,
      1760932423.7275298,
      1760932789.0479374,
      1760933180.082313,
      1760933512.3672676,
      1760933877.6171925,
      1760934267.5610578,
      1760934636.8538213
    ]
  }
}